{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18. Convolutional Neural Network (CNN)\n",
    "One of the neural network types that can be used for NLP is a Convolutional Neural Network. Such a network is based on animal visual cortex and is traditionally used for computer vision. More recently, application in the field of natural language processing was also looked into and this seemed to work quite well. CNN's look at features of images to see if certain shapes of patterns can be found. When they do, a node in the network is fired. The application for nlp works well, because such a network can detect patterns in text as well. 'I like' or 'very much' (n-grams) for example, show the significance of certain combinations of words. http://www.davidsbatista.net/blog/2018/03/31/SentenceClassificationConvNets/\n",
    "\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/jupyterhub/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/jupyterhub/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/jupyterhub/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/jupyterhub/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/jupyterhub/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/jupyterhub/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Item Description</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40127</th>\n",
       "      <td>Counterfeits/Watches</td>\n",
       "      <td>emporio armani ar shell case ceram bracelet re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40126</th>\n",
       "      <td>Counterfeits/Watches</td>\n",
       "      <td>cartiertank ladi brand cartier seri tank gende...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40125</th>\n",
       "      <td>Counterfeits/Watches</td>\n",
       "      <td>patek philipp watch box patek philipp watch bo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40130</th>\n",
       "      <td>Counterfeits/Watches</td>\n",
       "      <td>breitl navitim cosmonaut replica watch inform ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40129</th>\n",
       "      <td>Counterfeits/Watches</td>\n",
       "      <td>emporio armani men ar dial color gari watch re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15401</th>\n",
       "      <td>Services/Money</td>\n",
       "      <td>canada cc get card number cvv expiri date name...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15402</th>\n",
       "      <td>Services/Money</td>\n",
       "      <td>uk debit card take chanc buy uk visa debit car...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15403</th>\n",
       "      <td>Services/Money</td>\n",
       "      <td>itali card detail high valid fresh itali card ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15404</th>\n",
       "      <td>Services/Money</td>\n",
       "      <td>centurionblack cc get us centurion cc card num...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15391</th>\n",
       "      <td>Services/Money</td>\n",
       "      <td>buy coin vanilla reload send moneypak code zip...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Category  \\\n",
       "40127  Counterfeits/Watches   \n",
       "40126  Counterfeits/Watches   \n",
       "40125  Counterfeits/Watches   \n",
       "40130  Counterfeits/Watches   \n",
       "40129  Counterfeits/Watches   \n",
       "...                     ...   \n",
       "15401        Services/Money   \n",
       "15402        Services/Money   \n",
       "15403        Services/Money   \n",
       "15404        Services/Money   \n",
       "15391        Services/Money   \n",
       "\n",
       "                                        Item Description  category_id  \n",
       "40127  emporio armani ar shell case ceram bracelet re...            0  \n",
       "40126  cartiertank ladi brand cartier seri tank gende...            0  \n",
       "40125  patek philipp watch box patek philipp watch bo...            0  \n",
       "40130  breitl navitim cosmonaut replica watch inform ...            0  \n",
       "40129  emporio armani men ar dial color gari watch re...            0  \n",
       "...                                                  ...          ...  \n",
       "15401  canada cc get card number cvv expiri date name...           29  \n",
       "15402  uk debit card take chanc buy uk visa debit car...           29  \n",
       "15403  itali card detail high valid fresh itali card ...           29  \n",
       "15404  centurionblack cc get us centurion cc card num...           29  \n",
       "15391  buy coin vanilla reload send moneypak code zip...           29  \n",
       "\n",
       "[15000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import pandas as pd\n",
    "from preprocessing import PreProcessor\n",
    "\n",
    "pp = PreProcessor()\n",
    "\n",
    "df = pd.read_csv('Structured_DataFrame_Sample_500.csv', index_col=0)\n",
    "df['Item Description'] = df['Item Description'].apply(lambda d: pp.preprocess(str(d)))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2))\n",
    "features = tfidf.fit_transform(df['Item Description'])\n",
    "labels = df.Category\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94722    g peruvian flake best cocain high grade peruvi...\n",
       "38485    european paypal account x insid account test s...\n",
       "15551    two co hash oil pen profession manufactur co h...\n",
       "83348    furanylfentanyl power cousin fentanyl heroin g...\n",
       "2346     growityourself growschrank homebox q im komple...\n",
       "                               ...                        \n",
       "97143    uncut potent pink dutch speed g product nice d...\n",
       "82703    g premium moroccan hash uk uk one gram love mo...\n",
       "90008    zstrain magic mushroom cap welcom fellow breth...\n",
       "14381    g ethylphenid ep pleas read care intern bulk o...\n",
       "12030    mg cooki add item one mg cooki add item cooki ...\n",
       "Name: Item Description, Length: 10050, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, labels, df.index, test_size=0.33, random_state=0)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7006 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# convert list of tokens/words to indexes\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. sequence lenght:  265\n"
     ]
    }
   ],
   "source": [
    "# get the max sentence lenght, needed for padding\n",
    "max_input_lenght = max([len(x) for x in sequences_train])\n",
    "print(\"Max. sequence lenght: \", max_input_lenght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad all the sequences of indexes to the 'max_input_lenght'\n",
    "data_train = pad_sequences(sequences_train, maxlen=max_input_lenght, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data tensor: (3015, 265)\n",
      "Shape of train label tensor: (3015, 9)\n"
     ]
    }
   ],
   "source": [
    "# Encode the labels, each must be a vector with dim = num. of possible labels\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "labels_encoded_train = le.transform(y_train)\n",
    "categorical_labels_train = to_categorical(labels_encoded_train, num_classes=None)\n",
    "print('Shape of train data tensor:', data_train.shape)\n",
    "print('Shape of train label tensor:', categorical_labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test data tensor: (1485, 265)\n",
      "Shape of test labels tensor: (1485, 9)\n"
     ]
    }
   ],
   "source": [
    "# pre-process test data\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "x_test = pad_sequences(sequences_test, maxlen=max_input_lenght)\n",
    "\n",
    "labels_encoded_test = le.transform(y_test)\n",
    "categorical_labels_test = to_categorical(labels_encoded_test, num_classes=None)\n",
    "print('Shape of test data tensor:', x_test.shape)\n",
    "print('Shape of test labels tensor:', categorical_labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with random word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 265)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_dynamic (Embedd (None, 265, 3000)    21021000    main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Conv_dynamic_3 (Conv1D)         (None, 263, 100)     900100      embedding_layer_dynamic[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv_dynamic_4 (Conv1D)         (None, 262, 100)     1200100     embedding_layer_dynamic[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv_dynamic_5 (Conv1D)         (None, 261, 100)     1500100     embedding_layer_dynamic[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_dynamic_3 (MaxPoolin (None, 1, 100)       0           Conv_dynamic_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_dynamic_4 (MaxPoolin (None, 1, 100)       0           Conv_dynamic_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_dynamic_5 (MaxPoolin (None, 1, 100)       0           Conv_dynamic_5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_dynamic_3 (Flatten)     (None, 100)          0           MaxPooling_dynamic_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_dynamic_4 (Flatten)     (None, 100)          0           MaxPooling_dynamic_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_dynamic_5 (Flatten)     (None, 100)          0           MaxPooling_dynamic_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 300)          0           Flatten_dynamic_3[0][0]          \n",
      "                                                                 Flatten_dynamic_4[0][0]          \n",
      "                                                                 Flatten_dynamic_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 9)            2709        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,624,009\n",
      "Trainable params: 24,624,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from convnets_utils import *\n",
    "\n",
    "model_1 = get_cnn_rand(3000, len(word_index)+1, max_input_lenght, 30)\n",
    "print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "history = model_1.fit(x=data_train, y=categorical_labels_train, batch_size=50, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The kernel keeps dying when I try to train the network. I have tried tweaking the parameters such as the batch size, but nothing seems to work. I don't know how to continue with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
