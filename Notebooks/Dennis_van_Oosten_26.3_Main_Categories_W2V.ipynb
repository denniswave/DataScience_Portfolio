{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 26. Main Categories - Word2Vec\n",
    "For comparison, we want to check the result without balancing with word2vec and main categories, since we didn't know the score of this combination yet.\n",
    "\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Item Description</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Services</td>\n",
       "      <td>month huluplu gift code month huluplu code wor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Services</td>\n",
       "      <td>pay tv sky uk sky germani hd tv much cccam ser...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Services</td>\n",
       "      <td>offici account creator extrem tag submiss fix ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Services</td>\n",
       "      <td>vpn tor sock tutori setup vpn tor sock super s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Services</td>\n",
       "      <td>facebook hack guid guid teach hack facebook ac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109585</th>\n",
       "      <td>Drugs</td>\n",
       "      <td>gr purifi opium list gramm redefin opium pefec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109586</th>\n",
       "      <td>Weapons</td>\n",
       "      <td>ship ticket order ship one gun bought must bou...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109587</th>\n",
       "      <td>Drugs</td>\n",
       "      <td>gram white afghani heroin full escrow gram whi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109588</th>\n",
       "      <td>Drugs</td>\n",
       "      <td>gram white afghani heroin full escrow gram whi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109589</th>\n",
       "      <td>Drugs</td>\n",
       "      <td>heroin stamp bag pc bundl heroin stamp bag pc ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109563 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category                                   Item Description  \\\n",
       "0       Services  month huluplu gift code month huluplu code wor...   \n",
       "1       Services  pay tv sky uk sky germani hd tv much cccam ser...   \n",
       "2       Services  offici account creator extrem tag submiss fix ...   \n",
       "3       Services  vpn tor sock tutori setup vpn tor sock super s...   \n",
       "4       Services  facebook hack guid guid teach hack facebook ac...   \n",
       "...          ...                                                ...   \n",
       "109585     Drugs  gr purifi opium list gramm redefin opium pefec...   \n",
       "109586   Weapons  ship ticket order ship one gun bought must bou...   \n",
       "109587     Drugs  gram white afghani heroin full escrow gram whi...   \n",
       "109588     Drugs  gram white afghani heroin full escrow gram whi...   \n",
       "109589     Drugs  heroin stamp bag pc bundl heroin stamp bag pc ...   \n",
       "\n",
       "        category_id  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "109585            1  \n",
       "109586           11  \n",
       "109587            1  \n",
       "109588            1  \n",
       "109589            1  \n",
       "\n",
       "[109563 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from preprocessing import PreProcessor\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "pp = PreProcessor()\n",
    "\n",
    "df = pd.read_csv('../Data/Structured_DataFrame_Main_Categories.csv', index_col=0)\n",
    "df['Item Description'] = df['Item Description'].apply(lambda d: pp.preprocess(str(d)))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73407, 2)\n",
      "(36156, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"Item Description\"], df.Category, test_size=0.33, random_state=0)\n",
    "\n",
    "data_train = {'Category': y_train, 'Item_Description': X_train}\n",
    "df_train = pd.DataFrame(data_train)\n",
    "print(df_train.shape)\n",
    "\n",
    "data_test = {'Category': y_test, 'Item_Description': X_test}\n",
    "df_test = pd.DataFrame(data_test)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "def word2vec(corpus, size):\n",
    "    tokenized = [word_tokenize(row) for row in corpus]\n",
    "    model = Word2Vec(tokenized, size=size, workers=8)\n",
    "    vectors = []\n",
    "    for i, row in enumerate(tokenized):\n",
    "        sentence_vectors = [model.wv[word] for word in row if word in model.wv]\n",
    "        if len(sentence_vectors) == 0:\n",
    "            vectors.append(np.random.uniform(low=-1, high=1, size=(128,)))\n",
    "        else:\n",
    "            sentence_vector = np.average(sentence_vectors, axis=0)\n",
    "            vectors.append(sentence_vector)\n",
    "    return vectors, model\n",
    "\n",
    "def w2vTransform(sentence, model):\n",
    "    sentence_vectors = [model.wv[word] for word in word_tokenize(sentence) if word in model.wv]\n",
    "    if len(sentence_vectors) == 0:\n",
    "        return np.random.uniform(low=-1, high=1, size=(128,))\n",
    "    return np.average(sentence_vectors, axis=0)\n",
    "\n",
    "X_train, model = word2vec(df_train.Item_Description, 128)\n",
    "y_train = df_train.Category.values\n",
    "X_test = df_test.Item_Description.apply(lambda x: w2vTransform(x, model)).tolist()\n",
    "y_test = df_test.Category.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = LinearSVC()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.922281225799314\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Services       1.00      0.10      0.18        31\n",
      "             Drugs       0.82      0.79      0.81       705\n",
      "         Forgeries       0.72      0.69      0.71       675\n",
      "           Tobacco       0.67      0.61      0.63       275\n",
      "      Counterfeits       0.96      1.00      0.98     30807\n",
      "              Data       0.73      0.12      0.21       192\n",
      "       Information       0.82      0.76      0.79       323\n",
      "       Electronics       0.47      0.57      0.52       725\n",
      "Drug paraphernalia       0.38      0.12      0.19       642\n",
      "             Other       0.67      0.57      0.62       129\n",
      "           Jewelry       0.44      0.01      0.02       474\n",
      "           Weapons       0.49      0.53      0.51       837\n",
      "              Info       0.89      0.66      0.76       134\n",
      "         Chemicals       0.65      0.46      0.54       207\n",
      "\n",
      "         micro avg       0.92      0.92      0.92     36156\n",
      "         macro avg       0.69      0.50      0.53     36156\n",
      "      weighted avg       0.91      0.92      0.91     36156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=df['Category'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
